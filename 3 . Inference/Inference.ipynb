{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a91f34-d00e-4821-9cc7-04fab5f2d646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from easyocr import Reader\n",
    "import time\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aca563a-4335-4657-9f44-a813fac8ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIDENCE_THRESHOLD = 0.4\n",
    "COLOR = (0, 255, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ba0208-1c35-4fdc-939f-e420edaf0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_number_plates(image, model, display=False):\n",
    "    start = time.time()\n",
    "    # pass the image through the model and get the detections\n",
    "    detections = model.predict(image)[0].boxes.data\n",
    "\n",
    "    # check to see if the detections tensor is not empty\n",
    "    if detections.shape != torch.Size([0, 6]):\n",
    "\n",
    "        # initialize the list of bounding boxes and confidences\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "\n",
    "        # loop over the detections\n",
    "        for detection in detections:\n",
    "            # extract the confidence (i.e., probability) associated\n",
    "            # with the prediction\n",
    "            confidence = detection[4]\n",
    "\n",
    "            # filter out weak detections by ensuring the confidence\n",
    "            # is greater than the minimum confidence\n",
    "            if float(confidence) < CONFIDENCE_THRESHOLD:\n",
    "                continue\n",
    "\n",
    "            # if the confidence is greater than the minimum confidence, add\n",
    "            # the bounding box and the confidence to their respective lists\n",
    "            boxes.append(detection[:4])\n",
    "            confidences.append(detection[4])\n",
    "\n",
    "        print(f\"{len(boxes)} Number plate(s) have been detected.\")\n",
    "        # initialize a list to store the bounding boxes of the\n",
    "        # number plates and later the text detected from them\n",
    "        number_plate_list= []\n",
    "\n",
    "        # loop over the bounding boxes\n",
    "        for i in range(len(boxes)):\n",
    "            # extract the bounding box coordinates\n",
    "            xmin, ymin, xmax, ymax = int(boxes[i][0]), int(boxes[i][1]),int(boxes[i][2]), int(boxes[i][3])\n",
    "            # append the bounding box of the number plate\n",
    "            number_plate_list.append([[xmin, ymin, xmax, ymax],confidences[i]])\n",
    "\n",
    "            # draw the bounding box and the label on the image\n",
    "            #cv2.rectangle(image, (xmin, ymin), (xmax, ymax), COLOR, 2)\n",
    "            #text = \"Number Plate: {:.2f}%\".format(confidences[i] * 100)\n",
    "            #cv2.putText(image, text, (xmin, ymin - 5),cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR, 2)\n",
    "\n",
    "            if display:\n",
    "                # crop the detected number plate region\n",
    "                number_plate = image[ymin:ymax, xmin:xmax]\n",
    "                # display the number plate\n",
    "                cv2.imshow(f\"Number plate {i}\", number_plate)\n",
    "\n",
    "        end = time.time()\n",
    "        # show the time it took to detect the number plates\n",
    "        print(f\"Time to detect the number plates: {(end - start) * 1000:.0f} milliseconds\")\n",
    "        # return the list containing the bounding\n",
    "        # boxes of the number plates\n",
    "        return number_plate_list\n",
    "    # if there are no detections, show a custom message\n",
    "    else:\n",
    "        print(\"No number plates have been detected.\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "689d5098-d1c3-4c5e-b34b-db0f6d112949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_number_plates(image_or_path, reader,number_plate_list, write_to_csv=False):\n",
    "\n",
    "    start = time.time()\n",
    "    # if the image is a path, load the image; otherwise, use the image\n",
    "    image = cv2.imread(image_or_path) if isinstance(image_or_path, str) else image_or_path\n",
    "\n",
    "    for i, box in enumerate(number_plate_list):\n",
    "        # crop the number plate region\n",
    "        np_image = image[box[0][1]:box[0][3], box[0][0]:box[0][2]]\n",
    "\n",
    "        # detect the text from the license plate using the EasyOCR reader\n",
    "        detection = reader.readtext(np_image, paragraph=True)\n",
    "\n",
    "        if len(detection) == 0:\n",
    "            # if no text is detected, set the `text` variable to an empty string\n",
    "            text = \"\"\n",
    "        else:\n",
    "            # set the `text` variable to the detected text\n",
    "            text = str(detection[0][1])\n",
    "\n",
    "        # update the `number_plate_list` list, adding the detected text\n",
    "        number_plate_list[i].append(text)\n",
    "\n",
    "    if write_to_csv:\n",
    "        # open the CSV file\n",
    "        csv_file = open(\"number_plates.csv\", \"w\")\n",
    "        # create a writer object\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        # write the header\n",
    "        csv_writer.writerow([\"image_path\", \"box\", \"text\"])\n",
    "\n",
    "        # loop over the `number_plate_list` list\n",
    "        for box, text in number_plate_list:\n",
    "            # write the image path, bounding box coordinates,\n",
    "            # and detected text to the CSV file\n",
    "            csv_writer.writerow([image_or_path, box, text])\n",
    "        # close the CSV file\n",
    "        csv_file.close()\n",
    "\n",
    "    end = time.time()\n",
    "    # show the time it took to recognize the number plates\n",
    "    print(f\"Time to recognize the number plates: {(end - start) * 1000:.0f} milliseconds\")\n",
    "\n",
    "    return number_plate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff029748-45a8-4c8d-b0dc-512d05800848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the image...\n",
      "---Going into detect_number_plates Function -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 number plate, 183.9ms\n",
      "Speed: 3.8ms preprocess, 183.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Number plate(s) have been detected.\n",
      "Time to detect the number plates: 1936 milliseconds\n",
      "---Coming out from detect_number_plates Function -----\n",
      "---Going into recognize_number_plates Function -----\n",
      "Time to recognize the number plates: 124 milliseconds\n",
      "---Coming out from recognize_number_plates Function -----\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mputText(image, confidence_, (box[\u001b[38;5;241m0\u001b[39m], box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m5\u001b[39m),cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.5\u001b[39m, COLOR, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     33\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mputText(image, text, (box[\u001b[38;5;241m0\u001b[39m], box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m15\u001b[39m),cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.5\u001b[39m, COLOR, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m         \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m file_extension \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mkv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.avi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.wmv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mov\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\condaenv\\lib\\site-packages\\ultralytics\\utils\\patches.py:55\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(winname, mat)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(winname: \u001b[38;5;28mstr\u001b[39m, mat: np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     48\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Displays an image in the specified window.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m        mat (np.ndarray): Image to be shown.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     \u001b[43m_imshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwinname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43municode_escape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"best.pt\")\n",
    "# initialize the EasyOCR reader\n",
    "reader = Reader(['en'], gpu=True)\n",
    "\n",
    "# path to an image or a video file\n",
    "file_path = \"1.jpeg\"\n",
    "# Extract the file name and the file extension from the file path\n",
    "_, file_extension = os.path.splitext(file_path)\n",
    "\n",
    "# Check the file extension\n",
    "if file_extension in ['.jpg', '.jpeg', '.png']:\n",
    "    print(\"Processing the image...\")\n",
    "\n",
    "    image = cv2.imread(file_path)\n",
    "    print(\"---Going into detect_number_plates Function -----\")\n",
    "    number_plate_list = detect_number_plates(image, model)\n",
    "    print(\"---Coming out from detect_number_plates Function -----\")\n",
    "    \n",
    "    #cv2.imshow('Image', image)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    # if there are any number plates detected, recognize them\n",
    "    if number_plate_list != []:\n",
    "        print(\"---Going into recognize_number_plates Function -----\")\n",
    "        number_plate_list = recognize_number_plates(file_path, reader,number_plate_list,write_to_csv=False)\n",
    "        print(\"---Coming out from recognize_number_plates Function -----\")\n",
    "        \n",
    "\n",
    "        for box, confidence , text in number_plate_list:\n",
    "            cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), COLOR, 2)\n",
    "            confidence_ = \"Number Plate: {:.2f}%\".format(confidence * 100)\n",
    "            cv2.putText(image, confidence_, (box[0], box[1] - 5),cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR, 2)\n",
    "            cv2.putText(image, text, (box[0], box[3] + 15),cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR, 2)\n",
    "        cv2.imshow('Image', image)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "elif file_extension in ['.mp4', '.mkv', '.avi', '.wmv', '.mov']:\n",
    "        print(\"Processing the video...\")\n",
    "\n",
    "        video_cap = cv2.VideoCapture(file_path)\n",
    "\n",
    "        # grab the width and the height of the video stream\n",
    "        frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "        # initialize the FourCC and a video writer object\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        writer = cv2.VideoWriter(\"output.mp4\", fourcc, fps,(frame_width, frame_height))\n",
    "\n",
    "        # loop over the frames\n",
    "        while True:\n",
    "            # starter time to computer the fps\n",
    "            start = time.time()\n",
    "            success, frame = video_cap.read()\n",
    "\n",
    "            # if there is no more frame to show, break the loop\n",
    "            if not success:\n",
    "                print(\"There are no more frames to process.\"\n",
    "                      \" Exiting the script...\")\n",
    "                break\n",
    "\n",
    "            number_plate_list = detect_number_plates(frame, model)\n",
    "\n",
    "            if number_plate_list != []:\n",
    "                number_plate_list = recognize_number_plates(frame, reader,number_plate_list)\n",
    "\n",
    "                for box, confidence , text in number_plate_list:\n",
    "                    cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), COLOR, 2)\n",
    "                    confidence_ = \"Number Plate: {:.2f}%\".format(confidence * 100)\n",
    "                    cv2.putText(frame, confidence_, (box[0], box[1] - 5),cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR, 2)\n",
    "                    cv2.putText(frame, text, (box[0], box[3] + 15),cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLOR, 2)\n",
    "\n",
    "            # end time to compute the fps\n",
    "            end = time.time()\n",
    "            # calculate the frame per second and draw it on the frame\n",
    "            fps = f\"FPS: {1 / (end - start):.2f}\"\n",
    "            cv2.putText(frame, fps, (50, 50),cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 8)\n",
    "\n",
    "            # show the output frame\n",
    "            cv2.imshow(\"Output\", frame)\n",
    "            # write the frame to disk\n",
    "            writer.write(frame)\n",
    "            # if the 'q' key is pressed, break the loop\n",
    "            if cv2.waitKey(10) == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "        # release the video capture, video writer, and close all windows\n",
    "        video_cap.release()\n",
    "        writer.release()\n",
    "        cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afaec71-7647-403f-94bf-3f5a636e9fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "condaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
